{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksWbxKF6FpXv",
        "outputId": "4d6adc7c-a66a-4001-c213-4c36a50ddd65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matmul.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matmul.cu\n",
        "\n",
        "\n",
        " #include <stdio.h>\n",
        "\n",
        "__global__ void matmul(float *A, float *B, float *C, int N)\n",
        "{\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if(row < N && col < N)\n",
        "    {\n",
        "        float sum = 0;\n",
        "        for(int k = 0; k < N;k++)\n",
        "            sum = sum + A[row * N + k] * B[N * k + col];\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "\n",
        "}\n",
        "int main()\n",
        "{\n",
        "  int N = 2;\n",
        "    size_t size = N * N *sizeof(float);\n",
        "    float A[] = {1,2,3,4};\n",
        "    float B[] = {5,6,7,8};\n",
        "    float C[4];\n",
        "\n",
        "    float *d_A,*d_B,*d_C;\n",
        "\n",
        "    cudaMalloc(&d_A,size);\n",
        "    cudaMalloc(&d_B,size);\n",
        "    cudaMalloc(&d_C,size);\n",
        "\n",
        "    cudaMemcpy(d_A,A,size,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B,B,size,cudaMemcpyHostToDevice);\n",
        "\n",
        "     dim3 blocks(N,N);\n",
        "    dim3 threads(1,1);\n",
        "\n",
        "    matmul<<<blocks,threads>>>(d_A,d_B,d_C,N);\n",
        "    cudaMemcpy(C,d_C,size,cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for(int i=0;i< N*N;i++)\n",
        "    {\n",
        "        printf(\" %f\",C[i]);\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matmul.cu -o matmul"
      ],
      "metadata": {
        "id": "E5MOqab2Gceu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matmul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjyp-mC1GTGo",
        "outputId": "1278261c-1f40-4e83-d7f8-fa6e0dd7f6c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 19.000000\n",
            " 22.000000\n",
            " 43.000000\n",
            " 50.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7skg7x6eGTDO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "veBtJ0ZcGTBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CPw3VVYGS-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cH68kkIjGS8r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}